{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Tensor\n",
    "#### Previously, we made a distinction between vectors (one-dimensional arrays) and matrices (two-dimensional arrays). When we start working with more complicated neural networks, we'll need to use a higher-dimensional arrays as well.\n",
    "\n",
    "#### In many neural network libraries, *n*-dimensional arrays are referred to as *tensors*, which is what we'll call them too.\n",
    "#### If I were writing an entire book about deep learning, I'd implement a full-featured `Tensor` class that overloaded Python's arithmetic operators and could handle a variety of other operations. Such an implementation would take a notebook on its own. Here we'll cheat and say that a `Tensor` is just a `list`. This is true in one direction - all our vectors and matrices and higher-dimensional analogues *are* lists. It is certainly not true in the other direction - most Python *lists* are not *n*-dimensional arrays in our sense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, let's write a helper function to find a tensor's *shape*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\n",
      "[3, 2]\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "Tensor = list\n",
    "def shape(tensor: Tensor) -> List[int]:\n",
    "    sizes: List[int] = []\n",
    "    while isinstance(tensor, list):\n",
    "        sizes.append(len(tensor))\n",
    "        tensor = tensor[0]\n",
    "    return sizes\n",
    "\n",
    "print(shape([1, 2, 3]))\n",
    "print(shape([[1,2], [3,4], [5,6]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Because tensors can have any number of dimensions, we'll typically need to work with them recursively. We'll do one thing in the one-dimensional case and recurse in the higher-dimensional case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "def is_1d(tensor: Tensor) -> bool:\n",
    "    \"\"\"\n",
    "    If tensor[0] is a list, it's a higher-order tensor. Otherwise, tensor is 1-dimensional (that is, a vector)\n",
    "    \"\"\"\n",
    "    return not isinstance(tensor[0], list)\n",
    "\n",
    "print(is_1d([1, 2, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which we can use to write a recursive `tensor_sum` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "def tensor_sum(tensor: Tensor) -> float:\n",
    "    \"\"\" Sums up all the values in the tensor\"\"\"\n",
    "    if is_1d(tensor):\n",
    "        return sum(tensor)\n",
    "    else:\n",
    "        return sum(tensor_sum(tensor_i) for tensor_i in tensor)\n",
    "\n",
    "print(tensor_sum([1, 2, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We'll create a couple of helper functions so that we don't have to rewrite this logic everywhere. The first applies a function elementwise to a single tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "from typing import Callable\n",
    "\n",
    "def tensor_apply(f: Callable[[float], float], tensor: Tensor) -> Tensor:\n",
    "    \"\"\" Applies f elementwise\"\"\" \n",
    "    if is_1d(tensor):\n",
    "        return[f(x) for x in tensor]\n",
    "    else:\n",
    "        return [tensor_apply(f, tensor_i) for tensor_i in tensor]\n",
    "\n",
    "print(tensor_apply(lambda x: x + 1, [1, 2, 3])) # So in this example, we are adding 1 to every instance of x - each tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can use this to write a function that creates a zero tensor with the same shape as a given tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "def zeros_like(tensor: Tensor) -> Tensor:\n",
    "    return tensor_apply(lambda _: 0.0, tensor)\n",
    "\n",
    "print(zeros_like([1, 2, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We'll also need to apply a function to corresponding elements from two tensors (which had better be the exact same shape, although we won't check that)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 7, 9]\n",
      "[4, 10, 18]\n"
     ]
    }
   ],
   "source": [
    "def tensor_combine(f: Callable[[float, float], float],\n",
    "                    t1: Tensor,\n",
    "                    t2: Tensor) -> Tensor:\n",
    "    \"\"\" Applies f to corresponding elements of t1 and t2\"\"\"\n",
    "    if is_1d(t1):\n",
    "        return [f(x, y) for x,y in zip(t1, t2)]\n",
    "    else:\n",
    "        return [tensor_combine(f, t1_i, t2_i) for t1_i, t2_i in zip(t1, t2)]\n",
    "\n",
    "import operator\n",
    "print(tensor_combine(operator.add, [1, 2, 3], [4, 5, 6]))\n",
    "print(tensor_combine(operator.mul, [1, 2, 3], [4, 5, 6]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
