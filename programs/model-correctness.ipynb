{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### These days approximately 5 babies out of 1,000 are named Luke, and the lifetime prevalence of leukemia is about 1.4%. If we believe these two factors are independent and apply he \"Luke is for leukemia\" test to 1 million people, we'd expect to see a confusion matrix like:\n",
    "\n",
    "|            |   Leukemia    |  No leukemia  | Total     |\n",
    "| ---------- | ------------- | ------------- | --------- |\n",
    "|   \"Luke\"   |      70       |     4,930     |   5,000   |\n",
    "| \"Not Luke\" |    13,930     |    981,070    |  995,000  |\n",
    "|   Total    |    14,000     |    986,000    | 1,000,000 |\n",
    "\n",
    "We can then use these to compute various statistics about model performance. For example, `accuracy` is defined as the fraction of currect predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98114\n"
     ]
    }
   ],
   "source": [
    "def accuracy(tp: int, fp: int, fn: int, tn: int) -> float:\n",
    "    correct = tp + tn\n",
    "    total = tp + fp + fn + tn\n",
    "    return correct / total\n",
    "print (accuracy(70, 4930, 13930, 981070))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N.B: \n",
    "`tp` stands for 'true positive'\n",
    "`fp` stands for 'false positive'\n",
    "`tn` stands for 'true negative'\n",
    "`fn` stands for 'false negative'\n",
    "### In the chart above:\n",
    "- Our `tp` is when the model correctly predicts `Leukemia` and `Luke`\n",
    "- Our `fp` is when the model incorrectly predicts `Leukemia` and `Luke`\n",
    "- Our `tn` is when the model correctly predicts `Not Leukemia` and `Not Luke`\n",
    "- Our `fn` is when the model incorrectly predicts `Not Leukemia` and `Not Luke`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It's common to look at the combination of `precision` and `recall`. Precision measures how accurate our `positive` predictions were:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.014\n"
     ]
    }
   ],
   "source": [
    "def precision(tp: int, fp: int, fn: int, tn: int) -> float:\n",
    "    return tp / (tp + fp)\n",
    "print(precision(70, 4930, 13930, 981070))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### And recall measures what fraction of the positives our model identified:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005\n"
     ]
    }
   ],
   "source": [
    "def recall(tp: int, fp: int, fn: int, tn: int) -> float:\n",
    "    return tp / (tp + fn)\n",
    "print(recall(70, 4930, 13930, 981070))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sometimes precision and recall are combined into the `F1 score`, which is defined as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(tp: int, fp: int, fn: int, tn: int) -> float:\n",
    "    p = precision(tp, fp, fn, tn)\n",
    "    r = recall(tp, fp, fn, tn)\n",
    "    return 2 * p * r / (p + r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usually the choice of a model involves a tradeoff between precision and recall. You can think of this as a tradeoff between false positives and false negatives. Saying \"yes\" too often will give you lots of false positives, saying \"no\" too often will give you lots of false negatives"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
